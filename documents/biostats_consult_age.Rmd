---
title: "biostats_consulting"
output:
  pdf_document:
    toc: yes
    latex_engine: "xelatex"
  word_document:
    toc: yes
  html_document:
    highlight: espresso
    toc: yes
date: "r Sys.Date()"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyr)
library(dplyr)
library(readr)
library(summarytools)
library(ggplot2)
library(gridExtra)
library(stringr)
library(Rtsne)
library(reshape2)
library(car)
library(gtsummary)
library(lubridate)
```

```{r, warning=FALSE}
# Load the dataset
data_2022 <- read_csv("/Users/debbiez/Downloads/cleaned_2022_survey_dta.csv")
data_2024 <- read_csv("/Users/debbiez/Downloads/cleaned_2024_survey_dta.csv")
#data_2022 <- read_csv("S:\\biostats_consulting_lab\\cleaned_2022_survey_dta.csv")
#data_2024 <- read_csv("S:\\biostats_consulting_lab\\cleaned_2024_survey_dta.csv")
```

```{r}
# Rename the specified variables and clean data_2022
data_2022_cleaned <- data_2022 %>%
  rename(
    dob = sec1_q1,
    gender = sec1_q4,
    highest_education = sec1_q5,
    employment_status = sec1_q6,
    marital_status = sec1_q7,
    household_income = sec1_q8,
    residence_area = sec1_q9,
    survey_location = sec1_q10,
    survey_duration = sec11_start,
    religious = sec11_q156,
    religion = sec11_q157,
    specified_other_religion = sec11_q157other,
    science_contradict = sec11_q158,
    science_or_religion = sec11_q159
  ) %>%
  select(-consent, -availability) %>%
  mutate(
    religion = case_when(
      religion %in% c("CCAP", "Traditional African religion") ~ "Other",
      religion %in% c("Seventh Day Adventist") ~ "Other Christian",
      religion == "Prefer not to answer" ~ "Prefer not to answer [do not read aloud]",
      TRUE ~ religion
    ),
    employment_status = if_else(is.na(employment_status), "Missing", employment_status)
  )

data_2022_cleaned$age_in_2022 <- 2022 - year(data_2022_cleaned$dob)
```

```{r}
data_2022_cleaned <- data_2022_cleaned %>%
  mutate(across(c(religion,science_or_religion, science_contradict, religious), 
                ~ replace_na(., "Missing")))

```

```{r}
# Clean and rename specified variables in data_2024
data_2024_cleaned <- data_2024 %>%
  # Rename variables
  rename(
    caseid = caseid,
    response_status = response_1,
    response_by = response_2,
    dob = birthdate,
    highest_education = educ_level,
    employment_status = employ_status,
    people_speak_to_daily = number_people,
    household_income = hh_income,
    specified_other_religion = religion_oth,
    call_status = call_status
  ) %>%
  
  # Select only the relevant variables
  select(
    dob, caseid, response_status, response_by, gender, highest_education, marital_status, parent_guardian, 
    employment_status, work_industry, people_speak_to_daily, 
    household_income, residence_area, religion, 
    specified_other_religion, call_status, survey_date
  ) %>%
  
  # Clean data by re-coding and handling missing values
  mutate(
    # Re-code religion variable by grouping similar categories
    religion = case_when(
      religion %in% c("Seventh Day Adventists", "Apostolic/New Apostlic Church", "Church of Christ",
                      "Gospel/NewTestament/Injili Church", "Salvation Army Church", "Assembly of God Church",
                      "Roho Church", "Church of God", "Jehovah's Witness", "Legio Maria Church", "NENO",
                      "Repentance and Holiness", "Pentecostal/ Protestant Church") ~ "Other Christian",
      religion == "Prefer not to answer [do not read aloud]" ~ "Prefer not to answer",
      religion == "Akorino" ~ "Other",
      religion == "Baptist Church" ~ "Baptist",
      TRUE ~ religion
    ),
    
    # Re-code employment_status variable
    employment_status = case_when(
      employment_status %in% c("Self-employed (includes agribusiness)", "Peasant farmer") ~ "Self-employed",
      TRUE ~ employment_status
    ),
    highest_education = case_when(
      highest_education == "Prefer not to answer" ~ "Prefer not to answer [do not read aloud]",
      TRUE ~ highest_education
    )
  ) %>%
  
  # Replace NA values in highest_education with "Missing"
  mutate(highest_education = replace_na(highest_education, "Missing")) %>%
  mutate(marital_status = replace_na(marital_status, "Missing"))%>%
  mutate(parent_guardian = replace_na(parent_guardian, "Missing"))%>%
  mutate(work_industry = replace_na(work_industry, "Missing"))%>%
  mutate(people_speak_to_daily = replace_na(people_speak_to_daily, "Missing"))%>%
  mutate(household_income = replace_na(household_income, "Missing"))%>%
  mutate(residence_area = replace_na(residence_area, "Missing"))%>%
  mutate(employment_status = replace_na(employment_status, "Missing"))%>%
  mutate(religion = replace_na(religion, "Missing"))

  
data_2024_cleaned <- data_2024_cleaned %>%
  left_join(data_2022_cleaned %>% select(caseid, gender, religion, dob), by = "caseid", suffix = c("_2024", "_2022")) %>%
  mutate(
    # 如果2024的gender是NA，用2022的gender进行填充
    gender_2024 = coalesce(gender_2024, gender_2022),
    # 如果gender仍为NA，则替换为"Unknown"
    gender_2024 = replace_na(gender_2024, "Unknown"),
    
    dob_2024 = coalesce(dob_2024,dob_2022),
    # 如果religion仍为NA，则替换为"Unknown"
    dob_2024 = replace_na(dob_2024, "Unknown")
  ) %>%
  
  # 移除gender_2022和religion_2022，保留处理过的gender_2024和religion_2024
  select(-gender_2022, -dob_2022) %>%
  rename(gender = gender_2024, dob = dob_2024)
data_2024_cleaned$age_in_2024 <- 2024 - year(data_2024_cleaned$dob)
```

```{r}
# Replace "Prefer not to answer [do not read aloud]" with "Prefer not to answer" across all columns
data_2024_cleaned <- data_2024_cleaned %>%
  mutate(across(everything(), ~str_replace(., "Prefer not to answer \\[do not read aloud\\]", "Prefer not to answer")))
data_2022_cleaned <- data_2022_cleaned %>%
  mutate(across(everything(), ~str_replace(., "Prefer not to answer \\[do not read aloud\\]", "Prefer not to answer")))
```


```{r}
# Display the first few rows of the cleaned datasets
head(data_2022_cleaned)
head(data_2024_cleaned)
```


```{r}
# Check for missing values in both datasets
missing_values_2022 <- sapply(data_2022_cleaned, function(x) sum(is.na(x)))
missing_values_2024 <- sapply(data_2024_cleaned, function(x) sum(is.na(x)))
print(missing_values_2022)
print(missing_values_2024)

# Get summary statistics for both datasets
summary(data_2022_cleaned)
summary(data_2024_cleaned)
```

```{r}
# Check case IDs in both datasets
caseid_2022 <- data_2022_cleaned$caseid
caseid_2024 <- data_2024_cleaned$caseid

# Filter the 2024 dataset to only include those who successfully followed up
successful_followup_2024 <- data_2024_cleaned %>%
  filter(response_status == "Answered the phone, correct respondent" & call_status == "Completed")

# Extract the case IDs of the successfully followed-up participants
caseid_successful_followup <- successful_followup_2024$caseid

# Identify participants present in both 2022 and successfully followed up in 2024
common_successful_followup <- intersect(caseid_2022, caseid_successful_followup)

# Identify participants in 2022 but not in the successfully followed-up group in 2024 (dropped out)
dropped_participants <- setdiff(caseid_2022, caseid_successful_followup)

# Identify participants in 2024 (successfully followed up) but not in 2022 (new participants)
new_participants <- setdiff(caseid_successful_followup, caseid_2022)

# Output the counts
cat("Number of participants successfully followed up in 2024: ", length(common_successful_followup), "\n")
cat("Number of participants who dropped out after 2022: ", length(dropped_participants), "\n")
cat("Number of new participants who joined in 2024: ", length(new_participants), "\n")
```

```{r}
# View unique values for key variables across both datasets
list(
  religion_2022 = unique(data_2022_cleaned$religion),
  religion_2024 = unique(data_2024_cleaned$religion_2024),
  highest_education_2022 = unique(data_2022_cleaned$highest_education),
  highest_education_2024 = unique(data_2024_cleaned$highest_education),
  employment_status_2022 = unique(data_2022_cleaned$employment_status),
  employment_status_2024 = unique(data_2024_cleaned$employment_status),
  marital_status_2022 = unique(data_2022_cleaned$marital_status),
  marital_status_2024 = unique(data_2024_cleaned$marital_status)
)
```
```{r}
data_2022_cleaned <- data_2022_cleaned %>%
  semi_join(data_2024_cleaned, by = "caseid")  # 仅保留2024中存在的caseid

data_2024_cleaned <- data_2024_cleaned %>%
  semi_join(data_2022_cleaned, by = "caseid")  # 仅保留2022中存在的caseid
```



```{r}
# Function to calculate percentage of missing values
calculate_missing_percentage <- function(data) {
  data %>%
    summarise(across(everything(), ~ sum(. == "Missing") / n() * 100)) %>%
    pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_percentage")
}

# Calculate missing percentages for both datasets
missing_2022 <- calculate_missing_percentage(data_2022_cleaned)
missing_2024 <- calculate_missing_percentage(data_2024_cleaned)

# Plot missing values for data_2022_cleaned
plot_2022 <- ggplot(missing_2022, aes(x = reorder(variable, -missing_percentage), y = missing_percentage)) +
  geom_bar(stat = "identity", fill = "red") +
  coord_flip() +
  labs(title = "Missing in data_2022", x = "Variables", y = "Missing Percentage (%)") +
  theme_minimal()

# Plot missing values for data_2024_cleaned
plot_2024 <- ggplot(missing_2024, aes(x = reorder(variable, -missing_percentage), y = missing_percentage)) +
  geom_bar(stat = "identity", fill = "red") +
  coord_flip() +
  labs(title = "Missing in data_2024", x = "Variables", y = "Missing Percentage (%)") +
  theme_minimal()

# Combine the two plots into one, displayed side by side
combined_plot <- grid.arrange(plot_2022, plot_2024, ncol = 2)

# Display the combined plot
combined_plot

```

```{r}
# Merge the datasets by caseid and create new variables indicating changes between 2022 and 2024
merged_data <- full_join(data_2022_cleaned, data_2024_cleaned, by = "caseid", suffix = c("_2022", "_2024")) %>%
  mutate(lost = if_else(is.na(response_status) | response_status != "Answered the phone, correct respondent", 1, 0)) %>%
  mutate(
    education_change = if_else(
      is.na(highest_education_2022) | is.na(highest_education_2024) | 
      highest_education_2022 == "Missing" | highest_education_2024 == "Missing", 
      3,  # Set as 3 when missing in either year
      if_else(highest_education_2022 != highest_education_2024, 1, 0)
    ),
    
    employment_change = if_else(
      is.na(employment_status_2022) | is.na(employment_status_2024) | 
      employment_status_2022 == "Missing" | employment_status_2024 == "Missing", 
      3,  # Set as 3 when missing in either year
      if_else(employment_status_2022 != employment_status_2024, 1, 0)
    ),
    
    income_change = if_else(
      is.na(household_income_2022) | is.na(household_income_2024) | 
      household_income_2022 == "Missing" | household_income_2024 == "Missing", 
      3,  # Set as 3 when missing in either year
      if_else(household_income_2022 != household_income_2024, 1, 0)
    ),
    
    residence_change = if_else(
      is.na(residence_area_2022) | is.na(residence_area_2024) | 
      residence_area_2022 == "Missing" | residence_area_2024 == "Missing", 
      3,  # Set as 3 when missing in either year
      if_else(residence_area_2022 != residence_area_2024, 1, 0)
    ),
    
    religion_change = if_else(
      is.na(religion_2022) | is.na(religion_2024) | 
      religion_2022 == "Missing" | religion_2024 == "Missing", 
      3,  # Set as 3 when missing in either year
      if_else(religion_2022 != religion_2024, 1, 0)
    ),
    
    residence_area_change = if_else(
      is.na(residence_area_2022) | is.na(residence_area_2024) | 
      residence_area_2022 == "Missing" | residence_area_2024 == "Missing", 
      3,  # Set as 3 when missing in either year
      if_else(residence_area_2022 != residence_area_2024, 1, 0)
    )
  ) %>%
  select(
    caseid, 
    dob_2022, gender_2022, 
    highest_education_2022, highest_education_2024, 
    marital_status_2022, marital_status_2024, 
    employment_status_2022, employment_status_2024, 
    household_income_2022, household_income_2024, 
    residence_area_2022, residence_area_2024, residence_area_change,
    religion_2022, religion_2024, 
    specified_other_religion_2022,
    response_status, response_by, 
    parent_guardian, science_or_religion,
    lost, religious,
    education_change, employment_change, income_change, residence_change, religion_change,age_in_2022
  )

# View the first few rows to verify the new order
head(merged_data)

```

```{r}
dfSummary(merged_data) %>% view()
```

```{r}
# Summarize the percentages of each change status (0, 1, 3) for each variable
change_percentages <- merged_data %>%
  summarize(
    education_change_0 = mean(education_change == 0, na.rm = TRUE) * 100,  # No change
    education_change_1 = mean(education_change == 1, na.rm = TRUE) * 100,  # Changed
    education_change_3 = mean(education_change == 3, na.rm = TRUE) * 100,  # Unknown

    employment_change_0 = mean(employment_change == 0, na.rm = TRUE) * 100,
    employment_change_1 = mean(employment_change == 1, na.rm = TRUE) * 100,
    employment_change_3 = mean(employment_change == 3, na.rm = TRUE) * 100,

    income_change_0 = mean(income_change == 0, na.rm = TRUE) * 100,
    income_change_1 = mean(income_change == 1, na.rm = TRUE) * 100,
    income_change_3 = mean(income_change == 3, na.rm = TRUE) * 100,

    residence_change_0 = mean(residence_change == 0, na.rm = TRUE) * 100,
    residence_change_1 = mean(residence_change == 1, na.rm = TRUE) * 100,
    residence_change_3 = mean(residence_change == 3, na.rm = TRUE) * 100,
    
    religion_change_0 = mean(religion_change == 0, na.rm = TRUE) * 100,
    religion_change_1 = mean(religion_change == 1, na.rm = TRUE) * 100,
    religion_change_3 = mean(religion_change == 3, na.rm = TRUE) * 100,
    
    residence_area_change_0 = mean(residence_area_change == 0, na.rm = TRUE) * 100,  # No change in residence area
    residence_area_change_1 = mean(residence_area_change == 1, na.rm = TRUE) * 100,  # Changed residence area
    residence_area_change_3 = mean(residence_area_change == 3, na.rm = TRUE) * 100   # Unknown/missing residence area
  )

change_percentages
```
```{r}
dfSummary(merged_data) %>% view()
```

```{r, warning=FALSE}
# Prepare data for pie charts
education_data <- merged_data %>%
  count(education_change) %>%
  mutate(percentage = n / sum(n) * 100)

employment_data <- merged_data %>%
  count(employment_change) %>%
  mutate(percentage = n / sum(n) * 100)

income_data <- merged_data %>%
  count(income_change) %>%
  mutate(percentage = n / sum(n) * 100)

residence_data <- merged_data %>%
  count(residence_change) %>%
  mutate(percentage = n / sum(n) * 100)

religion_data <- merged_data %>%
  count(religion_change) %>%
  mutate(percentage = n / sum(n) * 100)

residence_area_data <- merged_data %>%
  count(residence_area_change) %>%
  mutate(percentage = n / sum(n) * 100)

# Create pie charts for each change status
education_pie <- ggplot(education_data, aes(x = "", y = percentage, fill = factor(education_change))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(title = "Education Change Status", fill = "Status", y = "", x = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank()) +
  scale_fill_manual(values = c("green", "orange", "red"), 
                    labels = c("No Change", "Changed", "Missing"))

employment_pie <- ggplot(employment_data, aes(x = "", y = percentage, fill = factor(employment_change))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(title = "Employment Change Status", fill = "Status", y = "", x = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank()) +
  scale_fill_manual(values = c("green", "orange", "red"), 
                    labels = c("No Change", "Changed", "Missing"))

income_pie <- ggplot(income_data, aes(x = "", y = percentage, fill = factor(income_change))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(title = "Income Change Status", fill = "Status", y = "", x = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank()) +
  scale_fill_manual(values = c("green", "orange", "red"), 
                    labels = c("No Change", "Changed", "Missing"))

residence_pie <- ggplot(residence_data, aes(x = "", y = percentage, fill = factor(residence_change))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(title = "Residence Change Status", fill = "Status", y = "", x = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank()) +
  scale_fill_manual(values = c("green", "orange", "red"), 
                    labels = c("No Change", "Changed", "Missing"))

religion_pie <- ggplot(religion_data, aes(x = "", y = percentage, fill = factor(religion_change))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(title = "Religion Change Status", fill = "Status", y = "", x = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank()) +
  scale_fill_manual(values = c("green", "orange", "red"), 
                    labels = c("No Change", "Changed", "Missing"))

residence_area_pie <- ggplot(residence_area_data, aes(x = "", y = percentage, fill = factor(residence_area_change))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(title = "Residence Area Change Status", fill = "Status", y = "", x = "") +
  theme_minimal() +
  theme(axis.text.x = element_blank()) +
  scale_fill_manual(values = c("green", "orange", "red"), 
                    labels = c("No Change", "Changed", "Missing"))

# Arrange the pie charts in a 2 x 3 layout
grid.arrange(education_pie, employment_pie, income_pie, residence_pie, religion_pie, residence_area_pie, ncol = 3)

```

```{r}
# Split data into lost and followed groups
lost_data <- merged_data %>% filter(lost == 1) 
followed_data <- merged_data %>% filter(lost == 0)

# Function to prepare data for pie chart
prepare_pie_data <- function(data, variable) {
  data %>%
    count({{ variable }}) %>%
    mutate(percentage = n / sum(n) * 100)
}

# Function to create pie chart
create_pie_chart <- function(pie_data, title, variable_name) {
  ggplot(pie_data, aes(x = "", y = percentage, fill = factor({{ variable_name }}))) +
    geom_bar(stat = "identity", width = 1) +
    coord_polar("y", start = 0) +
    labs(title = title, fill = "Status", y = "", x = "") +
    theme_minimal() +
    theme(axis.text.x = element_blank()) +
    scale_fill_manual(values = c("green", "orange", "red"), 
                      labels = c("No Change", "Changed", "Missing"))
}

# Prepare data for pie charts for both groups
# For Lost Group
education_lost <- prepare_pie_data(lost_data, education_change)
employment_lost <- prepare_pie_data(lost_data, employment_change)
income_lost <- prepare_pie_data(lost_data, income_change)
residence_lost <- prepare_pie_data(lost_data, residence_change)
religion_lost <- prepare_pie_data(lost_data, religion_change)
residence_area_lost <- prepare_pie_data(lost_data, residence_area_change)

# For Followed Group
education_followed <- prepare_pie_data(followed_data, education_change)
employment_followed <- prepare_pie_data(followed_data, employment_change)
income_followed <- prepare_pie_data(followed_data, income_change)
residence_followed <- prepare_pie_data(followed_data, residence_change)
religion_followed <- prepare_pie_data(followed_data, religion_change)
residence_area_followed <- prepare_pie_data(followed_data, residence_area_change)

# Create pie charts for lost group
education_pie_lost <- create_pie_chart(education_lost, "Education Change", education_change)
employment_pie_lost <- create_pie_chart(employment_lost, "Employment Change", employment_change)
income_pie_lost <- create_pie_chart(income_lost, "Income Change", income_change)
residence_pie_lost <- create_pie_chart(residence_lost, "Residence Change", residence_change)
religion_pie_lost <- create_pie_chart(religion_lost, "Religion Change", religion_change)
residence_area_pie_lost <- create_pie_chart(residence_area_lost, "Residence Area Change", residence_area_change)

# Create pie charts for followed group
education_pie_followed <- create_pie_chart(education_followed, "Education Change", education_change)
employment_pie_followed <- create_pie_chart(employment_followed, "Employment Change", employment_change)
income_pie_followed <- create_pie_chart(income_followed, "Income Change", income_change)
residence_pie_followed <- create_pie_chart(residence_followed, "Residence Change", residence_change)
religion_pie_followed <- create_pie_chart(religion_followed, "Religion Change", religion_change)
residence_area_pie_followed <- create_pie_chart(residence_area_followed, "Residence Area Change", residence_area_change)

# Arrange the pie charts in two sets (Lost and Followed)
# Lost group: 2 rows x 3 columns
grid.arrange(education_pie_lost, employment_pie_lost, income_pie_lost, 
             residence_pie_lost, religion_pie_lost, residence_area_pie_lost, 
             ncol = 3, top = "Lost Group")

# Followed group: 2 rows x 3 columns
grid.arrange(education_pie_followed, employment_pie_followed, income_pie_followed, 
             residence_pie_followed, religion_pie_followed, residence_area_pie_followed, 
             ncol = 3, top = "Followed Group")

```
```{r}
# 将分类变量转换为因子
merged_data$highest_education_2022 <- as.factor(merged_data$highest_education_2022)
merged_data$employment_status_2022 <- as.factor(merged_data$employment_status_2022)
merged_data$household_income_2022 <- as.factor(merged_data$household_income_2022)
merged_data$residence_area_2022 <- as.factor(merged_data$residence_area_2022)
merged_data$gender_2022 <- as.factor(merged_data$gender_2022)
merged_data$marital_status_2022 <- as.factor(merged_data$marital_status_2022)
merged_data$religion_2022 <- as.factor(merged_data$religion_2022)
merged_data$lost <- as.factor(merged_data$lost)
merged_data$science_or_religion <- as.factor(merged_data$science_or_religion)

# 创建一个新的数据框，移除包含 "Missing" 和 "Prefer not to answer" 的行
clean_data <- merged_data %>%
  filter(
    !highest_education_2022 %in% c("Missing") &
    !employment_status_2022 %in% c("Missing") &
    !household_income_2022 %in% c("Missing") &
    !residence_area_2022 %in% c("Missing") &
    !gender_2022 %in% c("Missing") &
    !marital_status_2022 %in% c("Missing") &
    !religion_2022 %in% c("Missing")
    )
# 删除 specified_other_religion_2022 和 response_by 列
clean_data <- clean_data %>%
  select(-specified_other_religion_2022, -response_by)

# 查看清理后的数据
print(dim(clean_data))  # 检查数据的行数和列数

```

```{r}
# 在清理后的数据上拟合全模型
clean_data$age_in_2022 <- as.numeric(clean_data$age_in_2022)
clean_model <- glm(lost ~ highest_education_2022 + employment_status_2022 + household_income_2022 + residence_area_2022 + gender_2022 + marital_status_2022 + religion_2022+age_in_2022, data = clean_data, family = binomial)
# 输出模型结果
summary(clean_model)
```

```{r}
# 拟合简化模型，仅保留显著变量
simplified_model <- glm(lost ~ employment_status_2022 + gender_2022 + religion_2022+age_in_2022, 
                        data = clean_data, family = binomial)
# 输出简化模型结果
summary(simplified_model)
```
```{r}
chi_square_test <- anova(simplified_model, clean_model, test = "Chisq")
print(chi_square_test)
```

```{r}
predicted_probs <- predict(simplified_model, type = "response")
predicted_class <- ifelse(predicted_probs > 0.5, 1, 0)

# 混淆矩阵
confusion_matrix <- table(Predicted = predicted_class, Actual = clean_data$lost)
print("Confusion Matrix:")
print(confusion_matrix)

# 绘制 ROC 曲线并计算 AUC
library(pROC)
roc_curve <- roc(clean_data$lost, predicted_probs)

# 绘制 ROC 曲线
plot(roc_curve, main = "ROC Curve", col = "blue", lwd = 2)
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")

# 输出 McFadden's R^2
null_model <- glm(lost ~ 1, data = clean_data, family = binomial)  # 空模型
r2_mcfadden <- 1 - (logLik(clean_model) / logLik(null_model))
cat("McFadden's R^2:", r2_mcfadden, "\n")
```

```{r}
# 如果 dependent variable 是多分类变量
library(nnet)
multinom_model <- multinom(lost ~ highest_education_2022 + employment_status_2022 + household_income_2022 + 
                   residence_area_2022 + gender_2022 + marital_status_2022 + religion_2022+age_in_2022, data = clean_data)
summary(multinom_model)
```
```{r}
# 确保 lost 是整数型
clean_data$lost <- as.integer(clean_data$lost)

poisson_model <- glm(lost ~ highest_education_2022 + employment_status_2022 + household_income_2022 + 
                   residence_area_2022 + gender_2022 + marital_status_2022 + religion_2022+age_in_2022, 
                     data = clean_data, family = poisson)
summary(poisson_model)

```


```{r}
# Load necessary libraries
library(dplyr)
library(ggplot2)

# Define the categorical variables for conversion to dummy variables
categorical_vars <- c("household_income_2022", "highest_education_2022", "employment_status_2022", 
                      "residence_area_2022", "gender_2022", "marital_status_2022", "religion_2022")

# Combine Lost and Followed groups first and add group label
combined_data <- merged_data %>%
  mutate(group = if_else(lost == 1, "Lost", "Followed")) %>%
  select(all_of(categorical_vars), group) %>%
  filter(!if_any(all_of(categorical_vars), ~ . == "Missing"))

# Convert categorical variables to factors
combined_data <- combined_data %>%
  mutate(across(all_of(categorical_vars), as.factor))

# Apply model.matrix to the combined dataset (convert categorical variables to dummy variables)
combined_data_clean <- model.matrix(~ . - 1, data = combined_data) %>%
  as.data.frame()

# Add group column back to the cleaned data
combined_data_clean$group <- combined_data$group

# Remove the group column before running PCA
combined_data_for_pca <- combined_data_clean %>%
  select(-group)

# Remove columns with zero variance (constant columns)
combined_data_for_pca <- combined_data_for_pca[, apply(combined_data_for_pca, 2, var) != 0]

# Perform PCA on the cleaned data, scaling the variables
combined_pca <- prcomp(scale(combined_data_for_pca), center = TRUE, scale. = TRUE)

# Extract the first two principal components and add group labels back
pca_df <- as.data.frame(combined_pca$x[, 1:2])
pca_df$group <- combined_data_clean$group

# Plot the PCA results using ggplot2
ggplot(pca_df, aes(x = PC1, y = PC2, color = group)) +
  geom_point() +
  labs(title = "PCA: Lost vs Followed Groups", x = "Principal Component 1", y = "Principal Component 2") +
  theme_minimal()

```



```{r}
# Initial setup for categorical variables
categorical_vars <- c("household_income_2022", "highest_education_2022", "employment_status_2022", 
                      "residence_area_2022", "gender_2022", "marital_status_2022", "religion_2022")

# Combine Lost and Followed groups first and add group label
combined_data <- merged_data %>%
  mutate(group = if_else(lost == 1, "Lost", "Followed")) %>%
  select(all_of(categorical_vars), group) %>%
  filter(!if_any(all_of(categorical_vars), ~ . == "Missing"))

# Convert categorical variables to factors
combined_data <- combined_data %>%
  mutate(across(all_of(categorical_vars), as.factor))

# Apply model.matrix to the combined dataset (with consistent dummy variables for both groups)
combined_data_clean <- model.matrix(~ . - 1, data = combined_data) %>%
  as.data.frame()

# Add group column back to the cleaned data
combined_data_clean$group <- combined_data$group

# Remove the group column before running PCA
combined_data_for_pca <- combined_data_clean %>%
  select(-group)

# Identify and remove columns with zero variance
combined_data_for_pca <- combined_data_for_pca[, apply(combined_data_for_pca, 2, var) != 0]

# 1. Standardize the data
combined_data_for_pca_scaled <- scale(combined_data_for_pca)

# 2. Perform PCA on the scaled data
combined_pca_scaled <- prcomp(combined_data_for_pca_scaled, center = TRUE, scale. = TRUE)

# 3. Calculate explained variance
explained_variance <- combined_pca_scaled$sdev^2 / sum(combined_pca_scaled$sdev^2)

# 4. Plot the explained variance for each principal component
explained_variance_df <- data.frame(
  PC = seq_along(explained_variance),
  Variance = explained_variance
)

ggplot(explained_variance_df, aes(x = PC, y = Variance)) +
  geom_bar(stat = "identity") +
  labs(title = "Explained Variance by Principal Components", x = "Principal Component", y = "Variance Explained") +
  theme_minimal()

# 5. Extract the first two principal components and plot PCA
pca_df_scaled <- as.data.frame(combined_pca_scaled$x[, 1:2])
pca_df_scaled$group <- combined_data_clean$group

# Plot PCA results
ggplot(pca_df_scaled, aes(x = PC1, y = PC2, color = group)) +
  geom_point() +
  labs(title = "Scaled PCA: Lost vs Followed Groups", x = "Principal Component 1", y = "Principal Component 2") +
  theme_minimal()

# 6. Identify outliers based on PCA results
outliers <- pca_df_scaled %>%
  filter(PC1 < -10 | PC2 < -10)

# 7. Remove outliers and re-plot PCA without outliers
pca_df_cleaned <- pca_df_scaled %>%
  filter(PC1 > -10 & PC2 > -10)  # Assuming -10 is the threshold for outliers

# Re-plot PCA without outliers
ggplot(pca_df_cleaned, aes(x = PC1, y = PC2, color = group)) +
  geom_point() +
  labs(title = "PCA without Outliers: Lost vs Followed Groups", x = "Principal Component 1", y = "Principal Component 2") +
  theme_minimal()


```
```{r}
# Calculate the proportion of variance explained by each component
explained_variance <- combined_pca_scaled$sdev^2 / sum(combined_pca_scaled$sdev^2)

# Calculate the cumulative explained variance
cumulative_explained_variance <- cumsum(explained_variance)

# Plot the cumulative explained variance
plot(cumulative_explained_variance, type = "b", xlab = "Number of Components", ylab = "Cumulative Explained Variance",
     main = "Cumulative Explained Variance by Principal Components")

# Add a horizontal line for 80% explained variance
abline(h = 0.80, col = "red", lty = 2)
abline(h = 0.90, col = "blue", lty = 2)

# Determine how many components explain at least 80% variance
components_80 <- which(cumulative_explained_variance >= 0.80)[1]
components_90 <- which(cumulative_explained_variance >= 0.90)[1]

print(paste("Number of components to retain for 80% variance:", components_80))
print(paste("Number of components to retain for 90% variance:", components_90))

```

```{r}
# Convert categorical variables to dummy variables and remove rows containing "Missing"
combined_data <- merged_data %>%
  mutate(group = if_else(lost == 1, "Lost", "Followed")) %>%
  select(all_of(categorical_vars), group) %>%
  filter(!if_any(all_of(categorical_vars), ~ . == "Missing")) %>%
  mutate(across(all_of(categorical_vars), as.factor))

# Apply model.matrix to convert the categorical variables into dummy variables
combined_data_clean <- model.matrix(~ . - 1, data = combined_data) %>%
  as.data.frame()

# Remove duplicate rows before running t-SNE
combined_data_clean <- combined_data_clean %>%
  distinct()

# Extract the group information for later plotting
group_labels <- combined_data$group[1:nrow(combined_data_clean)]  # Ensure it matches the reduced dataset size

# Perform t-SNE on the dummy variables, setting a perplexity value (typically between 5 and 50)
set.seed(42)  # Set seed for reproducibility
tsne_results <- Rtsne(as.matrix(combined_data_clean), dims = 2, perplexity = 10, verbose = TRUE, max_iter = 1000)

# Convert t-SNE results into a data frame for plotting
tsne_df <- as.data.frame(tsne_results$Y)
colnames(tsne_df) <- c("Dim1", "Dim2")
tsne_df$group <- group_labels

# Plot the t-SNE results using ggplot2
ggplot(tsne_df, aes(x = Dim1, y = Dim2, color = group)) +
  geom_point() +
  labs(title = "t-SNE: Lost vs Followed Groups", x = "t-SNE Dimension 1", y = "t-SNE Dimension 2") +
  theme_minimal()

```
```{r}
data_2022_cleaned[data_2022_cleaned == "Missing"] <- NA
data_2024_cleaned[data_2024_cleaned== "Missing"] <- NA
dfSummary(data_2022_cleaned) %>% view()
```


```{r}
library(mice)

# Replace "Missing" with NA in the 2022 dataset only
data_2022_cleaned[data_2022_cleaned == "Missing"] <- NA

data_2022_cleaned <- data_2022_cleaned[, !names(data_2022_cleaned) %in% c("science_or_religion", "survey_duration")]

# Convert specified columns to factors in the 2022 dataset
data_2022_cleaned <- within(data_2022_cleaned, {
    highest_education = as.factor(highest_education)
    employment_status = as.factor(employment_status)
    household_income = as.factor(household_income)
    residence_area = as.factor(residence_area)
    gender = as.factor(gender)
    marital_status = as.factor(marital_status)
    religion = as.factor(religion)
    science_contradict = as.factor(science_contradict)
    religious = as.factor(religious)
})

method <- make.method(data_2022_cleaned)
method["highest_education"] <- "polyreg"
method["employment_status"] <- "polyreg"
method["household_income"] <- "polyreg"
method["residence_area"] <- "polyreg"
method["gender"] <- "logreg"         # binary categorical
method["marital_status"] <- "polyreg"
method["religion"] <- "polyreg"
method["science_contradict"] <- "polyreg"
method["religious"] <- "polyreg"
method["age_in_2022"] <- "pmm" 
# max_it = 100
imputed_data_2022 <- mice(data_2022_cleaned, m = 5, method = method, maxit = 100, seed = 500)
completed_data_2022 <- complete(imputed_data_2022, 1)

head(completed_data_2022)
dfSummary(completed_data_2022) %>% view()
```





```{r}
# 加载必要的库
library(dplyr)
library(kableExtra)

# 将字符型变量转换为因子型变量，但排除 'caseid' 和 'dob'
data_2022_cleaned <- data_2022_cleaned %>%
  mutate(across(where(is.character) & !c(caseid, dob), as.factor))
data_2024_cleaned <- data_2024_cleaned %>%
  mutate(across(where(is.character) & !c(caseid, dob), as.factor))
# 执行卡方检验或Fisher检验并带有进度条的双变量分析函数
perform_bivariate_tests <- function(data) {
  
  # 获取所有分类变量的列表（排除 'caseid' 和 'dob'）
  categorical_vars <- names(data)[sapply(data, is.factor)]
  
  # 创建一个空的数据框来存储结果
  results <- data.frame(
    Variable_1 = character(),
    Variable_2 = character(),
    Test = character(),
    P_value = numeric(),
    stringsAsFactors = FALSE
  )
  
  # 计算所有可能的比较次数（组合数 nC2）
  total_comparisons <- choose(length(categorical_vars), 2)
  
  # 初始化进度条
  pb <- txtProgressBar(min = 0, max = total_comparisons, style = 3)
  progress <- 0  # 初始化进度
  
  # 遍历所有分类变量对
  for (i in 1:(length(categorical_vars) - 1)) {
    for (j in (i + 1):length(categorical_vars)) {
      var1 <- categorical_vars[i]
      var2 <- categorical_vars[j]
      
      # 创建列联表，忽略 NA 值
      contingency_table <- table(data[[var1]], data[[var2]], useNA = "no")
      
      # 检查列联表是否有效（即每行和每列都至少有一个非零计数）
      if (all(rowSums(contingency_table) > 0) && all(colSums(contingency_table) > 0)) {
        
        # 检查列联表是否太大以至于无法进行Fisher检验
        if (prod(dim(contingency_table)) > 2e5) {
          # 对于较大的表使用卡方检验
          test_result <- chisq.test(contingency_table)
          p_value <- test_result$p.value
          test_used <- "Chi-Square Test (Large Table)"
        } else {
          # 执行卡方检验并检查预期计数
          test_result <- chisq.test(contingency_table)
          if (any(test_result$expected < 5)) {
            # 对较小的表使用Fisher精确检验，并使用 Monte Carlo 近似
            fisher_result <- fisher.test(contingency_table, simulate.p.value = TRUE, B = 1e5)  # B 是模拟的迭代次数
            p_value <- fisher_result$p.value
            test_used <- "Fisher's Exact Test (Simulated)"
          } else {
            # 如果预期计数足够，则使用卡方检验
            p_value <- test_result$p.value
            test_used <- "Chi-Square Test"
          }
        }
        
        # 将结果追加到数据框
        results <- rbind(results, data.frame(
          Variable_1 = var1,
          Variable_2 = var2,
          Test = test_used,
          P_value = round(p_value, 4)
        ))
      }
      
      # 更新进度条
      progress <- progress + 1
      setTxtProgressBar(pb, progress)
    }
  }
  
  # 关闭进度条
  close(pb)
  
  # 对 p 值进行 Benjamini-Hochberg (BH) 校正
  results$Adjusted_P_value <- p.adjust(results$P_value, method = "BH")
  
  # 返回整洁的结果表格
  results %>%
    kable() %>%
    kable_styling(full_width = FALSE, position = "center", bootstrap_options = c("striped", "hover", "condensed"))
}


```


```{r}
# 示例用法：对数据集执行双变量分析
bir_2022 <- perform_bivariate_tests(data_2022_cleaned)
bir_2024 <- perform_bivariate_tests(data_2024_cleaned)

```
```{r}


# First, extract case IDs from 2024 data for those who answered correctly and completed the survey
followed_case_ids <- data_2024_cleaned %>%
  filter(response_status == "Answered the phone, correct respondent") %>%
  pull(caseid)

# Ensure categorical variables are factors
completed_data_2022 <- completed_data_2022 %>%
  mutate(
    highest_education = as.factor(highest_education),
    employment_status = as.factor(employment_status),
    household_income = as.factor(household_income),
    residence_area = as.factor(residence_area),
    gender = as.factor(gender),
    marital_status = as.factor(marital_status),
    religion = as.factor(religion)
  )
completed_data_2022$age_in_2022 <- as.numeric(completed_data_2022$age_in_2022)
# Logistic regression model to predict if a participant is followed up
logistic_followup_model <- glm(
  if_follow ~ highest_education + employment_status + household_income +
    residence_area + gender + marital_status + religion+ age_in_2022,
  data = completed_data_2022,
  family = binomial
)

# Display the summary of the logistic regression model
summary(logistic_followup_model)

```

```{r}
library(forcats)  # For factor lumping

data_2022_cleaned <- data_2022_cleaned %>%
  mutate(if_follow = if_else(caseid %in% followed_case_ids, 1, 0))
#Since none fo the factors above are significant, so try combining rare levels in employment_status and religion
data_2022_cleaned <- data_2022_cleaned %>%
  mutate(
    employment_status = fct_lump(employment_status, n = 3),  # Combine into top 3 most frequent levels
    religion = fct_lump(religion, n = 3)  # Combine into top 3 most frequent levels
  )
data_2022_cleaned$age_in_2022 <- as.numeric(data_2022_cleaned$age_in_2022)
# Run logistic regression with a reduced number of predictors
logistic_followup_model_simplified <- glm(
  if_follow ~ highest_education + employment_status + household_income + gender+age_in_2022,
  data = data_2022_cleaned,
  family = binomial
)


# Check model summary
summary(logistic_followup_model_simplified)
```


```{r}
# From this model, we can tell employment_other and gender being female are significant to not following up

# Load necessary library for random forest
library(randomForest)

# Set seed for reproducibility
set.seed(123)

# Random forest model to predict if a participant is followed up
data_2022_cleaned_no_na <- na.omit(data_2022_cleaned)
data_2022_cleaned_no_na$age_in_2022 <- as.numeric(data_2022_cleaned_no_na$age_in_2022)
random_forest_followup_model <- randomForest(
  as.factor(if_follow) ~ highest_education + employment_status + household_income +
    residence_area + gender + marital_status + religion+age_in_2022,
  data = data_2022_cleaned_no_na,
  importance = TRUE
)

# Display the random forest model summary
print(random_forest_followup_model)

# Variable importance plot
varImpPlot(random_forest_followup_model)
```

